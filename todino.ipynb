{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we use [NetworkX](https://nbviewer.org/github/massimo-nocentini/APAD-course/blob/master/ipynbs/networkx.ipynb) to show the graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout = open('output/output.txt','wt')\n",
    "print('Initiating...\\n')\n",
    "\n",
    "file_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "# Define a dictionary to hold and define all publications.\n",
    "graphs = {\n",
    "   'out-dblp_article': None,\n",
    "   'out-dblp_book': None,\n",
    "   'out-dblp_incollection': None,\n",
    "   'out-dblp_inproceedings': None,\n",
    "   'out-dblp_mastersthesis': None,\n",
    "   'out-dblp_phdthesis': None,\n",
    "   'out-dblp_proceedings': None,\n",
    "}\n",
    "\n",
    "# Define attributes for each type of publication to generate the venue.\n",
    "publication_attr = {\n",
    "   'out-dblp_article': ['year', 'journal'],\n",
    "   'out-dblp_book': ['year', 'title'],\n",
    "   'out-dblp_incollection': ['year', 'booktitle'],\n",
    "   'out-dblp_inproceedings': ['year', 'booktitle'],\n",
    "   'out-dblp_mastersthesis': ['year', 'title'],\n",
    "   'out-dblp_phdthesis': ['year', 'title'],\n",
    "   'out-dblp_proceedings': ['year', 'title'],\n",
    "}\n",
    "\n",
    "# Define the list of years.\n",
    "years = [1960,1970,1980,1990,2000,2010,2020,2023]\n",
    "\n",
    "# Define a dictionary to hold the publications.\n",
    "pub_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a graph from a CSV file.\n",
    "# It uses the separator || to split the publication attributes.\n",
    "def get_graph(filename):\n",
    "   B = nx.Graph()\n",
    "\n",
    "   with open(f'{file_dir}DATA/{filename}.csv') as file:\n",
    "      header = file.readline().replace('\\n', '').split(';')\n",
    "      authorIndex = header.index('author')\n",
    "      csv_reader = csv.reader(file, delimiter=';', quotechar='\"')\n",
    "      \n",
    "      for row in csv_reader:\n",
    "         authors = [author.strip() for author in str(row[authorIndex]).split('|')]\n",
    "\n",
    "         attributes = [row[header.index(attr)] if attr != '-' and str(row[header.index(attr)]) not in ('-', None, 'nan') else '' for attr in publication_attr[filename]]\n",
    "         # Add row only if there is at least the year.\n",
    "         if attributes[0] != '':\n",
    "            if '|' in str(attributes[0]):\n",
    "               attributes[0] = str(attributes[0]).split('|')[0]\n",
    "            attributes[0] = int(attributes[0])\n",
    "            \n",
    "            publication = ' || '.join([str(attr) for attr in attributes])\n",
    "\n",
    "            pub_dict[row[0]] = publication\n",
    "            # Add nodes and edges to the graph for every row.\n",
    "            B.add_nodes_from(authors, bipartite=0)\n",
    "            B.add_nodes_from([row[0]], bipartite=1)\n",
    "            B.add_edges_from([(author, row[0]) for author in authors])\n",
    "\n",
    "   # Define the position of the nodes in the graph in case of visualization.\n",
    "   pos = nx.bipartite_layout(B, list({n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}))\n",
    "   return B, pos\n",
    "\n",
    "# Returns the list of publications up to a given year (included).\n",
    "def get_publications_up_to_year(publications, year):\n",
    "   filtered_publications = []\n",
    "   for publication in publications:\n",
    "      pub_year = pub_dict[publication].split(' || ')[0]\n",
    "      if pub_year.isdigit() and int(pub_year) <= year:\n",
    "         filtered_publications.append(publication)\n",
    "   return filtered_publications\n",
    "\n",
    "# Returns the list of publications after a given year (excluded).\n",
    "def get_publications_after_year(publications, year):\n",
    "   filtered_publications = []\n",
    "   for publication in publications:\n",
    "      pub_year = pub_dict[publication].split(' || ')[0]\n",
    "      if pub_year.isdigit() and int(pub_year) > year:\n",
    "         filtered_publications.append(publication)\n",
    "   return filtered_publications\n",
    "\n",
    "# Returns the venue with the most publications and the number of publications.\n",
    "def get_venue_with_more_publications(publications, year):\n",
    "   publications = get_publications_up_to_year(publications, year)\n",
    "   venues = [pub_dict[publication].split(' || ')[-1].strip() for publication in publications if publication.split(' || ')[-1].strip() != '']\n",
    "   if not venues:\n",
    "      return None\n",
    "   # Create a series to count the number of publications for each venue.\n",
    "   venues_series = pd.Series(venues)\n",
    "   return venues_series.value_counts().idxmax(), venues_series.value_counts()[0]\n",
    "\n",
    "# BFS visit of a graph\n",
    "# Returns the nodes divided by layers and the eccentricity of the source (max distance from source)\n",
    "def bfs_visit(graph, source):\n",
    "    to_be_visited = {}  # dictionary to store for each node the distance from source\n",
    "    layers = defaultdict(list)  # each entry contains a list of nodes at distance key\n",
    "\n",
    "    # initialize dictionaries with source values\n",
    "    c_distance = 0\n",
    "    queue = [source]\n",
    "    to_be_visited[source] = c_distance\n",
    "    layers[c_distance] = [source]\n",
    "    # classic BFS implementation\n",
    "    while len(queue) > 0:\n",
    "        node = queue.pop(0)\n",
    "        c_distance = to_be_visited[node]\n",
    "        for neighbour in list(graph.adj[node]):\n",
    "            if neighbour not in to_be_visited:\n",
    "                queue.append(neighbour)\n",
    "                to_be_visited[neighbour] = c_distance + 1\n",
    "                layers[c_distance + 1].append(neighbour)\n",
    "\n",
    "    ecc = c_distance\n",
    "    return layers, ecc\n",
    "\n",
    "# Returns the diameter of a graph, using the optimized BFS visit\n",
    "def get_graph_diameter(graph):\n",
    "    if len(graph.nodes) == 1:\n",
    "       return 0\n",
    "    # find the highest degree node in the graph\n",
    "    max_connections = 0\n",
    "    source = None\n",
    "    for node in graph.nodes:\n",
    "        if len(graph.adj[node]) > max_connections:\n",
    "            max_connections = len(graph.adj[node])\n",
    "            source = node\n",
    "\n",
    "    layers, ecc = bfs_visit(graph, source)\n",
    "    i = ecc\n",
    "    l_bound = ecc\n",
    "    u_bound = 2 * ecc\n",
    "    while u_bound > l_bound:\n",
    "        # compute max_ecc_i(source)\n",
    "        i_nodes = layers[i]\n",
    "        max_ecc_i = 0\n",
    "        for node in i_nodes:\n",
    "            ecc_i = max(nx.single_source_shortest_path_length(graph, node).values())  # eccentricity\n",
    "            if ecc_i > max_ecc_i:\n",
    "                max_ecc_i = ecc_i\n",
    "\n",
    "        if max(l_bound, max_ecc_i) > 2 * (i - 1):   # lower bound > upper bound\n",
    "            return max(l_bound, max_ecc_i)\n",
    "        else:\n",
    "            l_bound = max(l_bound, max_ecc_i)\n",
    "            u_bound = 2 * (i - 1)\n",
    "\n",
    "        i -= 1\n",
    "\n",
    "    return l_bound\n",
    "\n",
    "# Returns the author with the most collaborations and the number of collaborations.\n",
    "def get_author_with_more_collaborations(graph, authors, year):\n",
    "   max_edges = 0\n",
    "   selected_node = None\n",
    "\n",
    "   for author in authors:\n",
    "      author_publications = get_publications_up_to_year([edge[1] for edge in graph.edges(author)], year)\n",
    "      multi_author_publications = [pub for pub in author_publications if len(graph[pub]) > 1]\n",
    "\n",
    "      if len(multi_author_publications) > max_edges:\n",
    "         max_edges = len(multi_author_publications)\n",
    "         selected_node = author\n",
    "\n",
    "   return selected_node, max_edges\n",
    "\n",
    "#QUESTION 1: Which is the venue having more publications?\n",
    "def question1(publications):\n",
    "  print(\"\\nWhich is the venue having more publications by year?\")\n",
    "  for year in years:\n",
    "    print(f'{year}: {get_venue_with_more_publications(publications, year)}')\n",
    "\n",
    "#QUESTION 2: Compute exactly the diameter of G\n",
    "def question2(graph, publications):\n",
    "   print(\"\\nWhich is the exact diameter of the biggest CC by year?\")\n",
    "\n",
    "   for year in years:\n",
    "      most_connected_graph = graph.copy()\n",
    "      most_connected_graph.remove_nodes_from(get_publications_after_year(publications, year))\n",
    "      GCCs = sorted(nx.connected_components(most_connected_graph), key=len, reverse=True)\n",
    "      most_connected_graph = most_connected_graph.subgraph(GCCs[0])\n",
    "\n",
    "      print(f'{year}: ({most_connected_graph.number_of_nodes()}, {get_graph_diameter(most_connected_graph)})')\n",
    "\n",
    "#QUESTION 3: Who is the author who had the largest number of collaborations? If author A and B collaborated twice, this count 2\n",
    "def question3(graph, authors):\n",
    "  print(\"\\nWho is the author who had the largest number of collaborations by year?\")\n",
    "  for year in years:\n",
    "    print(f'{year}: {get_author_with_more_collaborations(graph, authors, year)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First three questions for each file\n",
    "for filename in graphs.keys():\n",
    "   print(f'\\nFile: {filename}')\n",
    "   graphs[filename], pos = get_graph(filename)\n",
    "   authors = {n for n, d in graphs[filename].nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "   publications = set(graphs[filename]) - authors\n",
    "\n",
    "   print(f'Authors: {len(authors)}')\n",
    "   print(f'Publications: {len(publications)}')\n",
    "\n",
    "   question1(publications)\n",
    "   question2(graphs[filename], publications)\n",
    "   question3(graphs[filename], authors)\n",
    "\n",
    "   print('\\n__________________________________________________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 4: Merge all graphs and answer the same questions.\n",
    "print(f'\\nMerged graphs')\n",
    "\n",
    "for filename in graphs.keys():\n",
    "   graphs[filename], pos = get_graph(filename)\n",
    "\n",
    "# merge all graphs\n",
    "merged_graph = nx.compose_all(graphs.values())\n",
    "authors = {n for n, d in merged_graph.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "publications = set(merged_graph) - authors\n",
    "\n",
    "question1(publications)\n",
    "question2(merged_graph, publications)\n",
    "question3(merged_graph, authors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nWhich is the pair of authors who collaborated the most between themselves?\")\n",
    "# Which is the pair of authors who collaborated the most between themselves?\n",
    "authors_graph = nx.Graph()\n",
    "for publication in publications:\n",
    "   authors = [edge[1] for edge in merged_graph.edges(publication)]\n",
    "   for i in range(len(authors)):\n",
    "      for j in range(i + 1, len(authors)):\n",
    "         if authors_graph.has_edge(authors[i], authors[j]):\n",
    "            authors_graph[authors[i]][authors[j]]['weight'] += 1\n",
    "         else:\n",
    "            authors_graph.add_edge(authors[i], authors[j], weight=1)\n",
    "   \n",
    "# Get edges sorted by weight\n",
    "sorted_edges = sorted(authors_graph.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)\n",
    "if len(sorted_edges) > 0:\n",
    "   print(sorted_edges[0])\n",
    "else:\n",
    "   print('None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
